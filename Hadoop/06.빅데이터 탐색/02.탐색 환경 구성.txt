1. 하이브 설치
	CM 홈 -> Cluster1 콤보박스 -> 서비스 추가
	-> Hive 선택 -> 계속
	-> 종속성 집합 선택 페이지에서 HBase 선택 -> 계속
	-> 역할 할당 사용자 지정 페이지 -> WebHCat Server 제외하고 전부 server02에 지정 -> 계속
	-> 데이터베이스 설정 페이지 -> 기본값 유지 -> 테스트 연결 -> 계속
	-> 변경내용검토 페이지 -> 기본값 유지 -> 계속
	-> 첫 번째 실행 명령 페이지 -> 설치 완료 -> 계속 -> 완료

2. 우지 설치
	CM 홈 -> Cluster1 콤보박스 -> 서비스 추가
	-> Oozie 선택 -> 계속
	-> 종속성 집합 선택 페이지에서 HBase 선택 -> 계속
	-> 역할 할당 사용자 지정 페이지 -> server02에 지정 -> 계속
	-> 데이터베이스 설정 페이지 -> 기본값 유지 -> 테스트 연결 -> 계속
	-> 변경내용검토 페이지 -> 기본값 유지 -> 계속
	-> 첫 번째 실행 명령 페이지 -> 설치 완료 -> 계속 -> 완료

3. 휴 설치
	CM 홈 -> Cluster1 콤보박스 -> 서비스 추가
	-> Hue 선택 -> 계속
	-> 역할 할당 사용자 지정 페이지 -> server02에 지정 -> 계속
	-> 데이터베이스 설정 페이지 -> 기본값 유지 -> 테스트 연결 -> 계속
	-> 변경내용검토 페이지 -> 기본값 유지 -> 계속
	-> 첫 번째 실행 명령 페이지 -> 설치 완료 -> 계속 -> 완료

	# 설정 정보에서 Time Zone을 변경
	CM 홈 -> Hue -> 구성
	-> 검색: 시간대 -> time_zone 에서 "Asia/Seoul"로 변경 -> 변경 내용 저장

	# HBase 브라우저를 사용하기 위한 옵션 설정
	CM 홈 -> Hue -> 구성
	-> 검색: HBase Thrift 서버 -> HBase Thrift Server(server01) 선택

	# 설정 적용
	CM 홈 -> Hue -> 재시작

4. 스파크 설치
	CM 홈 -> Cluster1 콤보박스 -> 서비스 추가
	-> Spark 선택 -> 계속   # Spark(Standardalone) X
	-> 종속성 집합 선택 페이지에서 HBase 선택 -> 계속
	-> 역할 할당 사용자 지정 페이지 -> server02에 지정 -> 계속
	-> 변경내용검토 페이지 -> 기본값 유지 -> 계속
	-> 첫 번째 실행 명령 페이지 -> 설치 성공 -> 계속 -> 완료

	# 스파크를 YARN에서 작동하도록 구성했으므로 YARN 서비스와 클라이언트 구성을 재시작
	CM 홈 -> YARN(MR2 Included) -> 재시작

	# YARN 클라이언트 구성 배포
	CM 홈 -> YARN(MR2 Included) or Spark -> 활성화된 "클라이언트 구성 배포" 아이콘 클릭

	# 스파크 설치 확인, 스파크 히스토리 서버 접속, 어플리케이션 목록과 잡, 스테이지 모니터링 가능
	http://server02.hadoop.com:18088/

5. 클러스터 재시작
