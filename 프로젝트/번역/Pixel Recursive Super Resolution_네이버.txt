픽셀 재귀 슈퍼 해상도

추상적인

슈퍼 해상도는 고해상도 버전을 복구하기 위해 저분해능 사진을 인위적으로 확대하는 문제입니다. 고배율 요소의 시스템에서는 문제가 극적으로 불충분하며 많은 신뢰할 수 있는 고해상도 이미지가 지정된 저분해능 이미지와 일치할 수 있습니다. 특히, 기존의 슈퍼 해상도 기법은 문제의 다차원성과 그럴듯한 고해상도 이미지를 생성하기 위해 영상 합성에 적용해야 하는 강력한 이전 정보로 인해 이 체제에서 실패합니다.

본 연구에서는 이 문제를 해결하기 위해 픽셀 재귀 슈퍼 해상도 모델인 새로운 확률론적 네트워크 아키텍처를 제안한다.

우리는 이 모델이 대형 확대 요인에서 다양한 고해상도 이미지를 생성한다는 것을 입증한다.

게다가, 인간 평가 연구에서 우리는 이전의 방법들이 어떻게 인간의 관찰자들을 속이지 못하는지 보여준다. 그러나 이 확률론적 깊이 네트워크에서 샘플링된 고해상도 이미지는 순진한 인간 관찰자를 시간의 상당 부분을 속이는 것이다.


1.소개

슈퍼 해상도 문제는 고해상도의 해당 그럴듯한 이미지를 복구하기 위해 저분해능 사진을 인위적으로 확대하는 것이다[31].

작은 확대(예: 2)를 원하는 경우, 수퍼 해상도 기법은 자연 영상의 낮은 수준의 특성을 포착하는 이미지의 통계적 이전 모델을 구축하여 만족스러운 결과를 얻습니다 [41, 8, 16, 39, 22]

본 논문에서는 특히 입력량이 적고 고해상도 이미지를 정확하게 구성하는 데 사용할 수 있는 정보의 양이 매우 제한적인 슈퍼 해상도를 연구합니다(그림 1, 왼쪽 열).

따라서 문제가 충분히 설명되지 않으며 많은 신뢰할 수 있는 고해상도 이미지가 지정된 저해상도 입력 이미지와 일치할 수 있습니다.

고배율 시스템에서 최첨단 초고해상도 모델을 개발하는 것은 초해상도 모델을 개선하는 데 중요한 역할을 하며, 일반적으로 보다 나은 조건부 생성 이미지 모델을 구축하는 데 더욱 중요합니다 [44, 433, 30].

===============================
Google Brain Reserviron 프로그램 회원으로 작업
(g.co/brainresidency).

그림 1: 확률론적 픽셀 재귀적 슈퍼 해상도 모델은 연예인 얼굴 집합에 대해 엔드투엔드로 훈련된 것이다. 왼쪽 열에는 테스트 세트로부터의 88 저해상도 입력이 표시됩니다.

중간 및 마지막 열에는 우리 모델에서 예측한 32개의 이미지가 표시됩니다.

저희 모델은 사실적인 머리카락과 피부 세밀한 부분들을 합성하기 위해 강력한 얼굴 전리품을 포함하고 있습니다.
================================

확대 비율이 증가하면 슈퍼 해상도 모델은 텍스처, 에지 및 기타 저수준 통계량뿐만 아니라 객체, 뷰포인트, 조명 및 후두의 복잡한 변화를 고려해야 합니다. 확대 수준이 증가하면 소스 이미지에 세부 정보가 더 이상 존재하지 않으며, 예측 당면 과제가 세부 정보 복구에서 전환됩니다.

(예: 디콘볼루션 [23])를 사용하여 타당한 소설 상세정보를 합성한다 [33, 44].

그림 1 왼쪽 열의 낮은 해상도 이미지를 고려하십시오. 이러한 88 픽셀 이미지에서는 머리카락과 피부의 미세한 공간 세부 정보가 누락되어 보간 기법으로 충실하게 복원할 수 없습니다 [15].

그러나 얼굴과 얼굴의 일반적인 변동을 사전에 알고 통합함으로써, 스케치 예술가는 전문 소프트웨어 패키지를 사용하여 믿을 수 있는 세부사항을 상상하고 그릴 수 있습니다 [25].

이 논문에서는 로그 우도 목표를 사용하여 엔드투엔드로 훈련된 완전한 확률론적 모델이 그림 1 가운데 열에 표시된 32 3232 얼굴 이미지를 합성하여 그러한 아티스트의 역할을 어떻게 수행할 수 있는지를 보여준다. 이 모델에서 여러 샘플을 추출하면 고해상도 이미지가 생성되어 다중성이 나타나며, 저분해능 이미지에 해당하는 이미지의 다양성과 유사합니다. 인간 평가 연구에서 우리는 순진한 인간 관찰자가 깊은 네트워크와 평균 제곱 오류(MSE) 목표를 이용하여 정교한 슈퍼 해상도 모델의 출력과 실제 영상을 쉽게 구별할 수 있다는 것을 입증한다[21]. 그러나 확률론적 모델에서 추출한 샘플은 50%의 확률에 비해 최대 27:9%의 시간 동안 인간 관찰자를 속일 수 있다.

요약하자면, 이 논문의 주요 기고문은 다음과 같다.

 다중 모달 예측 측면에서 서술되지 않은 슈퍼 해상도 문제의 특성

확실하고 신뢰할 수 있는 다양한 비휘발광 고분해능 샘플을 생성하는 초해상도 문제에 맞춰진 새로운 확률론적 모델의 제안

 조건부 확률론적 모델의 경우 조건부 확률론적 디코더의 새로운 손실 용어를 제안하여 조건부 신호를 무시하지 않도록 한다.

 슈퍼 해상도(예: pSNR 및 SSIM)의 기존 측정기준이 충분히 명시되지 않은 슈퍼 해상도 체제에서 샘플 품질을 캡처하지 못한다는 것을 보여주는 인적 평가

우리는 관련 작업을 설명하고, 전통적인 목표를 사용하여 다중 모델 문제를 어떻게 해결하지 않는지 설명하면서 계속 진행한다. 그런 다음, 우리는 ResNet [14]와 Pixel-Nicon [43] 위에 새로운 확률론적 모델을 제안한다. 본 논문은 모델에 의해 생성된 고해상도 샘플의 다양성을 강조하고 인간 평가 연구를 통해 샘플의 품질을 설명한다.


2.관련업무

슈퍼 해상도는 컴퓨터 시력에 있어서 오랜 역사를 가지고 있습니다 [31].

보간[15]에 의존하는 방법은 구현하기 쉽고 광범위하게 사용되지만 선형 모형은 입력과 출력 사이의 복잡한 의존성을 표현할 수 없기 때문에 표현력의 부족으로 고생한다.

실제로 그러한 방법은 고주파 상세도를 적절히 예측하지 못해 고분해능 출력이 흐릿하게 되는 경우가 많다.

Sparity [2] 또는 가우스 혼합물과 같은 풍부한 영상으로 선형 방법을 향상시키면 방법 품질이 크게 향상되었으며, 마찬가지로, 가장자리 구배와 같은 저수준 영상 통계량을 활용하여 예측이 개선됩니다 [47]. 많은 작업이 패치 데이터베이스를 검색하여 이를 결합하여 확대된 이미지에서 그럴듯한 고주파 세부 정보를 생성하는 알고리즘에 대해 수행되었습니다 [9, 17]. 최근의 패치 기반 작업은 이미지에 사전 학습된 필터 사전을 만들고 효율적인 해싱 메커니즘으로 적절한 패치를 선택하여 기본적인 보간 방법을 개선하는 데 초점을 맞추고 있습니다[34].

그러한 사전 방법은 추론의 속도를 향상시켰으며 최첨단 기술과 견줄 만하다.

슈퍼 해상도의 또 다른 접근법은 추론 속도 요건을 포기하고 점점 더 높은 확대 요인에서 고해상도 이미지를 구축하는 데 집중하는 것이다. CNN(Convolutional Neuropean Network)은 명시적 사전 구성을 피하지만 필터 커널의 학습 계층을 통해 여러 단계의 추상화를 암시적으로 추출하는 문제에 대한 접근 방식을 나타냅니다.

동 외 [7]

3단 CNN에 MSE 손실을 입혔습니다.

김 외 [21]

깊이를 20개 레이어로 높이고 고해상도 이미지와 보간된 저분해능 영상 사이의 잔차만 학습하여 정확도를 향상시킵니다.

가장 최근에 SRResNet [26]은 많은 ResNet 블록을 사용하여 표준 슈퍼 해상도 벤치마크에서 pSNR 및 SSIM의 상태를 달성합니다. 우리는 조건부 네트워크와 캐치볼트 회귀 기준에도 유사한 설계를 사용합니다.

Johnson 등.[18]

모델의 예측과 지상의 진리 이미지를 위해 사전 훈련된 CNN의 활성화 사이에 유클리드 거리를 사용한다.

이른바 지각 손실을 사용하여, 그들은 초해상도 그리고 스타일 전달을 위해 피드-포워드 네트워크를 훈련시킨다. 브루나 외 [4]

또한 지각적 손실을 사용하여 슈퍼 해상도 네트워크를 훈련시키지만, 추론은 저수치 입력에 대한 구배 전파를 통해 이루어진다(예: [12]).

또 다른 유망한 방향은 네트워크 훈련을 위해 적적 손실을 사용하는 것이었다. 초해상도 네트워크는 합성된 고해상도 이미지가 진짜인지 가짜인지 구별하기 위해 2차 네트워크에 반대하여 훈련된다.

기존의 Lp 손실로 훈련된 네트워크(예: [21, 7)])는 흐릿한 이미지로 고통을 받고 있으며, 적적 손실을 사용하는 네트워크가 설득력 있고 높은 주파수 세부 정보를 예측합니다 [26, 49]. ø더비 외 [19]

적적 손실로 훈련을 받았지만 모델이 낮은 분해능 입력으로 다시 스케일다운되는 영상만 생성하도록 하는 암묵적 변환을 학습하도록 네트워크를 제한했습니다. ø더비 외 [19]

또한 복면을 쓴 자기 공격 모델을 탐색하지만 게이트 레이어는 포함하지 않고 다항 분포 대신 가우시안 혼합을 사용합니다. 덴턴 외 [5]

초고분해능 작업에 사용할 수 있는 영상 합성에 다중 스케일 상대 네트워크를 사용합니다.

생성적 적대적 네트워크 (GAN) [13]는 유망한 방향을 제공하지만, 그러한 네트워크들은 몇 가지 단점으로 어려움을 겪고 있다. 첫째, 적대적 네트워크의 훈련은 불안정하고 건전성을 높이기 위해 많은 방법들이 개발되고 있다.

둘째, GAN은 공통 고장 모드 붕괴 사례[29]로 인해 고통을 겪고 있으며, 이 경우 결과 모델에 의해 교육 데이터에서 사용할 수 있는 샘플의 다양성을 포착하지 못하는 샘플이 생성됩니다.

마지막으로, 확률론적 해석을 결과에 연관시키기가 어렵기 때문에 적대적 네트워크의 성능을 추적하는 것은 어렵다. 이러한 포인트는 교육 데이터 세트의 모든 다양성을 포괄하는 명확한 접근 방식을 통해 문제에 접근하는 동기를 부여한다.

PixelRNN과 PixelCNN[43, 44]은 긴 시퀀스로 표시하기 위해 영상 픽셀에 순서를 적용하는 확률론적 생성 모델입니다. 후속 픽셀의 확률은 이전에 관찰된 픽셀에 따라 결정됩니다.

PixelCNN[44]의 한 변형은 CIFAR-10 및 MNIST와 같은 학술 벤치마크에서 로그 우도 측면에서 최첨단 예측 능력을 확보했다. Pixel-CNN은 훈련에 로그 우도를 사용하기 때문에, 훈련 예에 무시할 수 있는 확률이 할당되면 그 모델에 불이익을 준다.

이와는 대조적으로, 적대적 네트워크는 비수치적 식별자를 속일 정도로만 배운다. 이 후자는 PixelCNN이 주어진 저분해능 영상과 연관될 수 있는 고해상도 영상의 많은 다양성을 예측할 수 있음을 암시합니다.

또한 교육 목표로 로그 우도를 사용하여 과장을 할 수 있습니다.
검증 집합에서 로그 확률을 단순히 비교함으로써 모델 제품군 내에서 모델을 찾기 위한 매개 변수 검색.


3. 확률론적 슈퍼 해상도

우리는 고해상도 이미지와 그에 상응하는 저분해능 이미지 사이의 통계적 의존성을 식별하는 확률론적 슈퍼 해상도 모델을 배우는 것을 목표로 한다.

x와 y가 저분해능 및 고분해능 이미지를 나타내고 y가 지상의 실제 고해상도 이미지를 나타내도록 합니다.

p(y j x)의 파라메트릭 모델을 학습하기 위해 D  f(x(i)로 표시된 저분해능 입력과 지상 실제 고분해능 출력 쌍이 포함된 대규모 데이터 세트를 활용합니다.

일부 고해상도 이미지에서 시작해 필요한 만큼 해상도를 낮추면 손쉽게 대규모 데이터 세트를 수집할 수 있다.

조건부 분포 p의 변수 를 최적화하기 위해 다음과 같이 정의된 조건부 로그 우도 목표를 최대화합니다.

O( j D) =
X
(x;y)2D
log p(y j x) : (1)

본 논문에서 논의된 핵심 문제는 효율적인 학습과 추론을 가능하게 하는 p(y j x)의 정확한 형태이며 현실적이지 않은 출력을 생성한다. 먼저 각 출력 픽셀이 입력되는 독립적인 확률적 프로세스를 통해 생성된다고 가정하는 픽셀 독립적인 모델에 대해 설명합니다. 우리는 왜 이러한 기법이 최적 이하의 초해상도 결과를 초래하는지 상세히 설명한다.

그런 다음, 출력 픽셀을 한 번에 하나씩 생성하여 출력 픽셀 간의 통계 의존성을 모델링할 수 있도록 하는 픽셀 재귀 슈퍼 해상도 모델을 설명하여 분해능이 매우 낮은 입력으로 인해 선명한 합성 이미지가 생성됩니다.


3.1. 픽셀 독립적인 슈퍼 해상도

확률론적 슈퍼 해상도 모델의 가장 단순한 형태는 입력값을 감안할 때 출력 픽셀이 조건적으로 독립적이라고 가정한다. 따라서 p(y j x) 요인의 조건부 분포는 독립적인 픽셀 예측의 산물입니다.

RGB 출력 y에 각각 3개의 색상 채널, 즉 y 2 R3M이 있는 M 픽셀이 있다고 가정해 보겠습니다.

log p(y j x) =
X3M
i=1
log p(yi j x) : (2)

문헌에서 일반적인 픽셀 예측 모델의 두 가지 형태인 연속 및 이산 픽셀 값을 모델링하는 가우스 분포와 다항 분포가 조사되었습니다.

가우스 사건에서

log p(yi j x) = 􀀀
1
22
kyi 􀀀 Ci(x)k22
􀀀 log
p
22 ; (3)

여기서 Ci(x)는 대각선 신경 네트워크를 통한 x의 비선형 변환의 iith 요소를 나타냅니다. 따라서 Ci(x)는 iT 출력 픽셀 yi에 대한 추정 평균이고 2는 분산을 나타냅니다.

분산은 종종 학습되지 않으며, 이 경우 (1)의 조건부 로그 우도를 최대화하면 데이터 세트 전체에서 픽셀과 채널 간에 yi와 Ci(x) 사이의 MSE가 최소화됩니다.

MSE 회귀 분석에 기초한 슈퍼 해상도 모델은 픽셀 독립 모델 제품군에 속합니다 [7, 21, 26].

암묵적으로, 신경 네트워크의 출력은 고정된 분산을 가진 가우시안 집합을 매개변수화한다.

동위원소성 다변수 가우시안(y j x)을 형성하므로 합동 분포 p(y j x)가 상상을 초월함을 쉽게 확인할 수 있습니다.

또는 출력 치수를 K 가능한 값(예: K = 256)으로 분리하고 각 픽셀에 대한 예측 모델로 다항 분포를 사용할 수 있습니다 [50]. 여기서 yi 2 f1; : : : 다항체 소프트맥스 연산자에 기초한 픽셀 예측 모델은 다음과 같습니다.

p(yi = k j x) =
expfCik(x)g
PK
v=1 expfCiv(x)g
; (4)

여기에서 색상 채널당 각 값에 대해 소프트맥스 중량 집합인 fwjkg3;K j=1;k=1의 네트워크를 사용하여 Cik(x)을 유도한다.

(4)의 p(yi j x)는 다차원 분포를 나타낼 수 있지만 픽셀 간의 조건부 의존성을 캡처할 수 없습니다. 즉, 조정을 필요로 하기 때문에 모델이 한 위치에서 다른 위치로 가장자리를 그리는 것 사이에서 선택할 수 없습니다.

==============================

데이터 집합 생성 방법
50%
50%
숙련된 모델의 샘플
L2 회귀 분석
교차 엔트로피
픽셀CNN

그림 2: 시뮬레이션된 데이터셋은 멀티모드 예측의 도전을 보여줍니다.

상단: 표본을 왼쪽 위 또는 오른쪽 아래 모서리로 랜덤하게 변환하는 합성 데이터 세트.

Bottom: 이 데이터셋에서 훈련된 다양한 알고리즘의 예

픽셀 독립적인 L2 회귀 분석 및 교차 엔트로피 모형은 단일 모드를 예측하지 못하며, 대신 이러한 샘플이 교육 세트에 존재하지 않더라도 두 개의 공간 위치의 혼합을 예측합니다.

반대로 PixelCNN은 상호 배제를 통해 양쪽 코너에서 자릿수를 예측합니다.

==========================================


3.2. 합성 다중모드 작업

조건부 이미지 모델링에서 픽셀 독립 모델이 어떻게 실패하는지 입증하기 위해 멀티모드 예측이 필요한 합성 데이터 세트를 만듭니다. 많은 조밀한 영상 예측 작업(예:

슈퍼 해상도 [31], 색화[50, 6] 및 깊이 추정 [37]에서 단일 모드를 예측할 수 있는 모델은 모드를 함께 혼합하는 모델보다 훨씬 선호됩니다. 예를 들어, 사과에 대한 강한 빨간색이나 녹색을 선택하는 작업에서는 훈련 세트에서 관찰된 모든 사과 색상의 얼룩진 평균을 반영하는 갈색 톤을 선택하는 것보다 더 좋다.

NAT은 간단한 멀티모드 MNIST 코너 데이터셋을 구성하여 이 문제의 해결 과제를 보여줍니다.

MNIST 코너는 상단 왼쪽 또는 하단 오른쪽 코너에 MNIST 디지트를 임의로 배치하여 구성합니다(그림 2, 상단). 여러 네트워크는 이 데이터셋의 개별 샘플을 예측하여 이 간단한 예제의 고유한 과제를 보여 줍니다.

이 장난감 예제의 배후 과제는 네트워크의 이미지 코너에서 개별 숫자를 독점적으로 예측하는 것이다.

L2 목표(즉, MSE 회귀)를 사용하여 중간 크기의 10단 간 신경망( 100K 매개변수)을 훈련하면 두 모드가 함께 혼합되는 흐릿한 영상 샘플이 생성됩니다(그림 2, L2).

즉, 데이터 세트에서는 예제 이미지에 두 모서리에 숫자가 포함되어 있지 않지만 이 모델은 이러한 표본의 혼합을 잘못 예측합니다. 이산형 픽셀 단위 교차 엔트로피로 대체하면 더 선명한 이미지가 생성되지만 마찬가지로 이미지 코너에서 숫자를 안정적으로 예측하지 못합니다(그림 2, 교차 엔트로피).


4. 픽셀 반복 슈퍼 해상도

예측 픽셀 간 조건부 독립성의 결여는 합성 예에서 이전의 확률론적 목표(Equations 3과 4)에 대한 중요한 고장 모드이다.

이 문제에 대한 한 가지 접근법은 다변량 가우스 혼합물 [52] 또는 비간접 그래픽 모델 [10]으로 출력 픽셀의 조건부 분포를 정의하는 것입니다.

두 조건부 분포 모두 계산적으로 비용이 많이 드는 출력 픽셀 간의 통계 의존성을 구성해야 합니다.

두 번째 접근법은 이미지 픽셀에 주문을 부과하여 체인 규칙을 사용하여 공동 분포를 추정하는 것입니다.

log p(y j x) =
MX
i=1
log p(yi j x; y<i) ; (5)

여기서 각 출력 치수의 생성은 입력 및 이전 출력 픽셀에 따라 결정됩니다 [24, 42].

우리는 conditioning1을 y <i>로 표기한다. 여기서 fy1; : : ; yi􀀀1g

이 접근법의 장점은 조건부 의존성의 정확한 형태가 유연하고 추론이 간단하다는 것이다.

PixelCNN은 로그 p(yi j x; y<i)에 대한 명확한 모델을 교묘하게 마스킹된 구성의 게이트된 계층적 체인으로 제공하는 확률적 모델입니다 [43, 44, 36].

PixelCNN의 목표는 영상에서 다중 형식과 픽셀 상관 관계를 캡처하는 것입니다.

실제로 MNIST 코너 데이터셋에서 PixelCNN을 교육하면 문제의 이중성을 성공적으로 캡처하고 단일 모서리에만 자리가 있는 샘플을 생성할 수 있습니다(그림 2, 픽셀-CNN).

중요한 것은 모형이 두 자릿수를 동시에 예측하지 못한다는 것입니다.

1색 영상에서 색 채널뿐만 아니라 공간 위치 모두에 순서를 지정해야 합니다. 컬러 영상에서 조절은 입력과 이전 공간 위치에서 출력된 픽셀 및 동일한 공간 위치의 픽셀을 기반으로 합니다.

==========================================

이전 네트워크!
(픽셀CNN)
HR을 기록합니다!
이미지
컨디셔닝!
네트워크(CNN)!
+ HR!
이미지

그림 3: 제안된 슈퍼 해상도 네트워크는 조건화 네트워크와 이전 네트워크로 구성됩니다.

Conditioning 네트워크는 각 고해상도(HR) 이미지 픽셀의 조건부 로그-확률을 예측하는 입력 및 출력 로짓으로 저분해능 이미지를 수신하는 CNN입니다.

이전 네트워크인 PixelCNN[44]는 이전의 확률적 예측(파선으로 표시됨)을 기반으로 예측을 수행합니다.

모델의 확률 분포는 이전 및 조건화 네트워크의 두 로그 집합의 합계에 추가하여 소프트max 연산자로 계산됩니다.

==============================================


PixelCNN을 초고해상도 문제에 적용하는 것은 낮은 해상도의 이미지 버전으로 컨디셔닝을 제공하기 위해 아키텍처를 수정해야 하는 간단한 애플리케이션입니다.

초기 실험에서 모델의 자동 반작용 분포는 저분해능 이미지의 조절을 대부분 무시한다는 것을 발견했습니다.

"최적화 과제"라고 하는 이 현상은 순차적 오토인코더 모델[3]의 맥락에서 쉽게 문서화되었다(자세한 내용은 [38, 40] 참조).

이 문제를 해결하기 위해 PixelCNN의 아키텍처를 저분해능 이미지의 조절에 따라 더욱 명시적으로 수정합니다.

특히, 문제를 자동 진행성 및 조건화 구성요소로 유도하는 최신 융접 모델 [20]을 제안합니다(그림 3).

이전 네트워크라고 하는 모델의 자동 진행 부분은 픽셀의 직렬 종속성을 캡처하는 반면, 조절 구성 요소는 낮은 해상도 이미지의 글로벌 구조를 캡처합니다.

구체적으로, 우리는 이전 네트워크를 PixelCNN으로, 그리고 조건화 네트워크는 이전에 슈퍼 해상도를 위해 사용되었던 심도 있는 공진 네트워크로 공식화한다[26].

입력 x 2 RL을 지정하면 Ai(x) : RL! RK는 iT 출력 픽셀이 취할 수 있는 K 가능한 값에 해당하는 로짓 값 벡터를 예측하는 조건화 네트워크를 나타냅니다. 마찬가지로, Let Bi(y <i) : Ri􀀀1! RK는 iith 출력 픽셀의 로짓 값 벡터를 예측하는 이전 네트워크를 나타냅니다.

우리의 확률론적 모델은 단순히 두 세트의 로그와 소프트맥스 연산자를 적용하여 iT 출력 픽셀에 대한 분포를 예측한다.

p(yi j x; y<i) = softmax(Ai(x) + Bi(y<i)) : (6)

A와 B의 파라미터를 공동으로 최적화하기 위해 확률적 경사도를 상승시켜 (1)의 조건부 로그 가능성을 극대화하였습니다.

즉, 우리는 (6) 모델의 예측과 yi 2 f1 : : :;Kg,

O1 =
X
(x;y)2D
MX
i=1

1[y
i ]T(Ai(x) + Bi(y
<i))
􀀀 lse(Ai(x) + Bi(y
<i))

;
(7)

여기서 lse()는 softmax의 분모 로그에 해당하는 log-sum-exp 연산자이며, 1[k]는 k번째 치수가 1로 설정된 K-차원 1-hot 표시기 벡터를 나타냅니다.

예비 실험에서 픽셀과 이전 고해상도 픽셀 사이의 통계적 상관 관계가 낮은 해상도 입력과의 상관 관계보다 더 강하기 때문에 (7)로 훈련된 모델은 조건화 네트워크를 무시하는 경향이 있습니다.

이 문제를 완화하기 위해, 우리는 조건화 네트워크가 최적화되도록 하는 우리의 목표에 추가적인 손실을 포함한다. 이 추가 손실은 소프트맥스(Ai(x)와 접지진실 라벨을 통해 컨디셔닝 네트워크의 예측 사이에 교차 엔트로피를 측정한다.

우리의 실험에서 최적화된 총 손실은 다음과 같이 형성된 교차 엔트로피 손실 2개의 합이다.

O2 =
X
(x;y)2D
MX
i=1

1[y
i ]T(2Ai(x) + Bi(y
<i))
􀀀 lse(Ai(x) + Bi(y
<i)) 􀀀 lse(Ai(x))

:
(8)

일단 네트워크가 훈련을 받으면 모델에서 샘플링이 간단합니다.

(6)을 사용하여 i = 1부터 시작하여 고해상도 픽셀을 먼저 샘플링합니다. 그런 다음 픽셀별로 픽셀을 진행하여 이전에 샘플링된 픽셀 값을 다시 네트워크에 공급하고 새로운 고해상도 픽셀을 그립니다.

각 픽셀의 세 채널이 순차적으로 생성됩니다.

또한 항상 가능성이 가장 큰 픽셀 값을 선택하고 온도 파라미터 > 0을 사용하여 분포 p의 농도가 조정되는 강화 소프트맥스에서 샘플링하는 탐욕 디코딩을 고려합니다.

p =
p(1=)
kp(1=)k1
:

샘플링 분포 p (yi j x; y <i)의 농도를 제어하려면 A와 B의 로그를 매개 변수로 나누면 됩니 다. . 참고로? 0으로 갈 때 분포는 모드로 수렴됩니다.


4.1. 마늘의 임용

픽셀 재귀 슈퍼 해상도 모델의 네트워크 아키텍처를 요약합니다.

조건화 아키텍처는 SRResNet [26]과(와) 설계가 비슷합니다.

조절 네트워크는 일련의 18􀀀30 ResNet blocks [14] 및 변환된 convolution layer [32]를 통해 낮은 분해능의 이미지를 얻는 피드-포워드 코볼루션 신경 네트워크이다.

마지막 계층은 11 corvolution을 사용하여 채널 수를 증가시켜 각 하위 픽셀에 대해 가능한 256개의 가능한 색상 채널 값에 대한 다항 분포를 예측합니다.

이전 네트워크 아키텍처는 각 계층에 32개의 채널이 있는 20개의 게이트 픽셀CNN 블록으로 구성됩니다 [44].

초고해상도 네트워크의 최종 계층은 조건화 및 이전 네트워크에서의 활성화 합계에서 소프트맥스 작동이다.

이 모델은 텐서플로[1]를 사용하여 제작되며 동기식 SGD 업데이트로 8개의 GPU에서 교육됩니다.

교육 세부 사항 및 아키텍처 매개 변수의 전체 목록은 부록 A를 참조하십시오.


5. 실험

우리는 중앙에서 잘라낸 면(CelebA [27])과 침실 이미지(LSUN 침상[48])를 포함하는 두 데이터셋에서 제안된 픽셀 재귀 슈퍼 해상도 방법의 효과를 평가한다.

두 데이터셋에서 우리는 훈련과 평가를 위한 입력 x와 출력 y를 제공하기 위해 바이큐빅 보간법을 사용하여 이미지의 크기를 88 및 3232픽셀로 조정합니다.

우리는 우리의 기술을 (1) 가장 가까운 N을 포함한 세 가지 기준과 비교한다.

예제를 기반으로 한 슈퍼 해상도[9], (2) ResNet L2; MSE 목표로 훈련된 Resnet 블록을 사용하는 깊은 신경망, (3) GAN 기반 수퍼 해상도 모델에 의해 구현된 유사한 인접 검색 기준선 침실 세트에서 GANbaseline의 결과는 경쟁이 치열하지 않기 때문에 제외되며, 이 모델은 얼굴을 위해 특별히 개발되었습니다.

가장 가까운 N. 기준선은 교육 세트 D = f(x(i), y(i)gNi=1을 검색하여 샘플 x에 대해 y를 계산하며 i = argmin에서 가장 가까운 분해능을 반환합니다.

가장 가까운 N. 기준은 예제 기반의 슈퍼 해상도 접근방식의 대표적인 결과이며, 모델이 교육 데이터 집합에서 순진한 룩업을 수행하는지 여부를 테스트하는 데 도움이 됩니다.

ResNet L2 기준선은 SRResNet [26]과 유사한 설계를 채택하여 이미지 유사성 메트릭2의 측면에서 최첨단 상태를 보고합니다.

가장 중요한 것은, 네트워크를 변경하여 입력의 바이큐빅 보간과 관련하여 잔차를 계산합니다 [21]. L2 회귀 분석은 상상도 할 수 없는 픽셀 독립적인 예측을 수행하는 최첨단 공진 네트워크와의 비교를 제공합니다.

GAN 슈퍼 해상도 기준선[11]은 조건부 GAN 아키텍처를 활용하며, 적법한 손실과 일관성 손실을 결합하여 예측 y의 저분해능 버전이 L1의 측정으로 x에 가깝도록 권장한다.

[11]에 의해 일관성 0:9로 지정된 두 손실 사이에 가중치가 있으며, 상대 손실의 경우 0:1로 지정되며, 우리는 안면 실험에서 이러한 손실들을 동일하게 유지합니다.

=====================================================

2 회귀 구조는 섹션 4.1의 조건화 네트워크와 거의 동일합니다.

약간의 변경은 네트워크가 RGB 공간의 경계 값을 예측하도록 하는 것입니다.

이러한 행동을 강제하기 위해, 최상위 계층은 하나가 아닌 세 개의 채널을 출력하고, RLU() 비선형성 대신 황갈색을 사용한다.

그림 4: 확률론적 픽셀 재귀 슈퍼 해상도 모델의 LSUN 침실 데이터 세트에 대한 훈련된 종단간 그림.

=======================================================


5.1. 슈퍼 해상도 샘플

픽셀 재귀 슈퍼 해상도에서 생성된 고해상도 샘플은 데이터 세트의 풍부한 구조를 캡처하고 지각적으로 신뢰할 수 있는 것으로 나타납니다(그림 1과 4, 부록 B 및 C).

슈퍼 해상도 모델에서 여러 번 샘플링하면 특정 저해상도 이미지에 대해 서로 다른 고해상도 이미지가 생성됩니다(그림 5; 부록 B 및 C). 정성적으로 모델의 샘플은 주어진 낮은 해상도 이미지에 해당하는 고유한 질적 특성을 가진 많은 그럴듯한 고해상도 이미지를 식별합니다.

면 데이터 세트에 대한 표본 간의 차이는 합성 데이터 세트에 나타나는 것보다 훨씬 덜 심각합니다. 이 경우 모드를 정리하지 못하면 완전한 오류가 표시됩니다.

샘플의 품질은 온도에 민감합니다(그림 6, 오른쪽 열).

그리스 해독( = 0)은 너무 매끄럽고 수평 및 수직 라인 아티팩트를 포함하는 샘플의 품질을 떨어뜨립니다.

원하는 고주파 성분을 포함하는 경향이 있지만 기본 온도( Samples = 1:0)의 샘플은 지각적으로 더 신뢰할 수 있습니다.

0:9에서 0:8 사이의 온도()를 조정하면 검체 품질 향상에 도움이 됩니다.

===========================================

그림 5: 픽셀 재귀 슈퍼 해상도 모델의 다양한 샘플. 왼쪽 열: 낮은 분해능 입력

오른쪽 열: 분해능이 낮은 입력에 따라  = 0:8인 다중 슈퍼 해상도 샘플.
============================================


5.2. 영상 유사성의 정량적 평가

유사성의 인간 지각 판단을 측정하려는 이미지 유사성을 정량화하기위한 많은 방법이 존재한다 [45, 46, 28].

우리는 pSNR과 MS-SSIM을 사용하여 지상 진실에 비해 우리 모델의 예측 정확도를 정량화했다 (표 1). 예측 된 이미지 품질에 대한 자체 시각적 평가가 이러한 이미지 유사성 측정 기준과 일치하지 않음을 발견했습니다. 예를 들어, 바이 큐빅 보간법은 샘플이 상당히 불량 해 보였음에도 불구하고 상대적으로 높은 메트릭을 달성했습니다.

이 결과는 새로운 세부 사항이 합성 될 때 pSNR과 SSIM이 수퍼 해상도 품질에 대한 잘못된 판단을 제공한다는 최근의 관찰과 일치한다 [26, 18].

또한 그림 6은 모델 샘플의 지각 품질이 음의 로그 가능성 (NLL)과 반드시 ​​일치하지 않는 것을 강조합니다.

NLL이 작 으면 모델이 해당 이미지에 더 큰 확률의 질량을 할당했음을 의미합니다.

욕심 많은, bicubic 및 회귀면은 더 나쁜 지각 품질을 나타낼지라도 모델에 의해 선호됩니다.

다음으로 일관성을 측정하여 고해상도 샘플이 저해상도 입력과 얼마나 잘 일치하는지 측정했습니다.

일관성은 저해상도 입력 이미지와 고해상도 추정의 바이 큐빅 다운 샘플링 버전 사이의 L2 거리로 정량화됩니다.

낮은 일관성은 저해상도 이미지와의 우수한 대응을 나타냅니다.

이것은 GAN [11]의 명백한 목적이다.

픽셀 재귀 모델은 L2 회귀 모델 및 바이 큐빅 보간과 일치하는 일관성을 달성하여 모델이 다양한 샘플을 생성 했음에도 불구하고 샘플이 저해상도 이미지로 크게 제한된다는 것을 나타냅니다.

가장 중요한 점은, 모델이 명시 적으로이 기준을 최적화하지 않더라도 픽셀 재귀 모델은 GAN [11]보다 우수한 일관성을 달성했습니다 .3

일관성 측정은 픽셀 재귀 모델이 가장 가까운 훈련 샘플을 순진하게 복사 하는지를 결정하는 중요한 제어 실험을 추가로 제공했습니다.

픽셀 재귀 모델이 가장 가까운 훈련 샘플을 복사 한 경우에는 가장 가까운 N의 일관성을 나타냅니다.

모델은 픽셀 재귀 모델과 동일합니다.

대신에 픽셀 재귀 모델은 가장 일관성있는 값을 가지므로 모델이 가장 가까운 훈련 사례를 순진하게 복사하는 것이 아니라는 것을 나타냅니다.


5.3. 인간에 대한 지각적 평가

자동화된 정량적 조치가 우리의 지각적 판단과 일치하지 않는 것을 감안하여, 우리는 초해상도 알고리즘의 효과를 평가하기 위해 인간 연구를 수행했다.

특히, 각 모델로부터 주어진 고해상도 샘플이 얼마나 신뢰할 수 있는지 결정하기 위해 군중 공급 작업자에 대해 강제 선택 실험을 수행했습니다.

[50]에 따라 각 작업자는 실제 이미지와 모델로부터 상응하는 예측을 제공받았고, "어떤 이미지가 카메라에서 나온 것 같습니까?"라는 질문을 받았습니다.

우리는 Amazon Mechanical Turk에 있는 283명의 작업자에 대해 이 연구를 수행했고 통계는 각 수퍼 해상도 알고리즘에 대해 40명의 고유한 작업자에 걸쳐 발생되었습니다.4

===================================

3목적의 가중치를 높여 GAN의 일관성을 개선할 수 있음에 유의한다.

일관성 기간의 가중치를 높이면 영상에서 인식 품질이 저하되지만 일관성이 향상됩니다.

그럼에도 불구하고, 픽셀 재귀 모델에 의해 생성된 영상은 온도 범위에서 판단된 인간보다 일관성과 지각 품질 모두에서 우수합니다.

4 특히 각 근로자에게는 강제 선택 결정을 내리는 데 1초가 주어졌습니다.

근로자들은 10개의 연습문제를 가지고 회의를 시작했고, 그 동안 피드백을 받았다.

연습 쌍은 결과에서 계산되지 않았다.

연습 쌍 후, 각 작업자는 45개의 추가 쌍을 보여주었다.

이 두 쌍의 부분집합은 노동자가 주의를 기울이고 있는지 지속적으로 확인하기 위해 고안된 단순하고 황금색 질문이었다. 금빛 질문에 잘못 답한 직원들의 데이터가 삭제되었다.

===========================

===============================
그림 6: 슈퍼 해상도 모델 비교 왼쪽에서 오른쪽으로 열에는 입력, 접지 진실, 가장 가까운 N이 포함됩니다.

(가장 가까운 이웃의 슈퍼 해상도), GAN, 바이큐빅 상향 샘플링, ResNet L2(MSE로 최적화된 신경망), 탐욕스러운 디코딩은 픽셀 재귀적 모델이며, 다양한 온도()로 샘플링됩니다.

영상 아래에 음의 로그 확률이 보고됩니다.

최상의 로그-확률성은 이미지가 좋지 않더라도 바이큐빅 상향 샘플링 및 탐욕 디코딩과 관련이 있습니다.
================================

===============================
CellebA pSNR SSIM MS-SSIM 일관성 % 풀링됨
Bicubic 28.92 0.84 0.76 0.006 –
가장 가까운 N. 28.18 0.73 0.66 0.024 –
ResNet L2 29.16 0.90 0.90 0.004 4:0  0:2
GAN [11] 28.19 0.72 0.67 0.029 8:5  0:2
 = 1:0 29.09 0.84 0.86 0.008 11:00:1
 = 0:9 29.08 0.84 0.85 0.008 10:4  0:2
 = 0:8 29.08 0.84 0.86 0.008 10:2  0:1
LSUN pSNR SSIM MS-SSIM 일관성 % 풀링됨
Bicubic 28.94 0.70 0.002 –
가장 가까운 N. 28.15 0.49 0.45 0.040 –
ResNet L28.74 0.75 0.003 2:1  0:1
 = 1:0 28.92 0.58 0.60 0.016 17:7  0:4
 = 0:9 28.92 0.59 0.59 0.017 22:4  0:3
 = 0:8 28.93 0.59 0.58 0.018 27:90:3
=================================

표 1: 잘라낸 CellebA(상단) 및 LSUN 침실(하단) 데이터셋에 대한 테스트 결과가 8~32~3232로 확대되었습니다. 우리는 견본과 지면 진실 사이에 pSNR, SSIM, MS-SSIM을 보고한다.

일관성은 저분해능 입력과 그에 상응하는 저분해능 출력 사이의 MSE를 측정합니다. % Fooled 보고서는 알고리즘의 출력이 얼마나 자주 군중 소싱 연구에서 인간을 속이는지를 측정합니다. 50%는 완전히 혼동됩니다.

표 1은 인간이 실제 영상이라고 잘못 믿었던 주어진 알고리즘에 대한 표본의 비율을 나타낸다.

완벽한 알고리즘은 인간을 50%의 비율로 속일 수 있다는 것에 주목하라. L2 회귀 모형은 시간의 2~4%를 인간을 속였고 GAN[11]은 그 시간의 8.5%를 인간으로 속였다.

화소 재귀 모델은 얼굴과 침실 시간의 11.0%와 27.9%를 각각 속였는데 이는 최신 회귀 모델을 크게 앞질렀다.

중요한 것은 샘플 채취 온도의 선택이 샘플의 품질에 큰 영향을 미쳤다는 점과 동시에 인간이 속은 시간의 일부에 영향을 미친다는 점입니다.

그럼에도 불구하고 픽셀 재귀 모델은 모든 온도에서 가장 강력한 기준 모델인 GAN을 능가했다.

가장 우수하고 최악의 사례의 순위 목록은 부록 D에 바보 같은 비율과 함께 재현되어 있다.


6. 합병

우리는 고주파 세부 정보가 누락됨에 따라 문제가 크게 설명되지 않는 높은 확대 비율의 슈퍼 해상도 연구를 지지한다.

비광택 슈퍼 해상도 출력을 생성하는 모든 모델은 그러한 다중 모드 시스템에서 작동하기 위해 누락된 내용을 합리적으로 예측해야 한다. 우리는 적은 입력으로 슈퍼 해상도를 다루는 완전 확률론적 방법을 제시하며, 88 이미지마저도 선명한 3232 이미지로 확대될 수 있음을 입증한다.

당사의 기술은 회귀 목표 또는 적적 손실을 최적화하는 기준을 포함하여 몇 가지 강력한 기준보다 우수한 성능을 제공합니다.

우리는 픽셀 재귀 모델의 샘플이 인간에게 더 그럴듯하게 보인다는 것을 보여주는 인간 평가 연구를 수행하며, 더 일반적으로 pSNR과 SSIM과 같은 일반적인 지표는 확대 비율이 클 때 인간의 판단과 관련이 없다.


승인

우리는 통찰력 있는 논평과 논의를 위해 ̈라론 반 데 오드, 산더 다이글먼, 구글 브레인 팀에 감사한다.