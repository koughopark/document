1. SmartCar 에이전트 생성
	# 플럼의 에이전트를 만들려면 플럼이 인식할 수 있는 특정 디렉터리에 이름이 {Agent 고유이름}.conf 형식인 파일을 생성하면 되는데,
	# 파일럿 프로젝트에서는 CM에서 제공하는 플럼 구성 정보 설정을 통해 에이전트를 편리하게 생성할수 있다.

	CM홈 -> flume 클릭 -> 구성 클릭    # CM에서 제공하는 플럼의 기본 에이전트
	중간에 [구성파일] 부분 찾기    # 이부분을 수정해서 플럼 에이전트를 쉽게 생성가능하다.
	Agent 이름: SmartCar_Agent
	구성파일: 기존내용 삭제, 새내용 입력 ->
	[구성파일]
	# 1. SmartCar 에이전트 생성
	# 플럼의 에이전트에서 사용할 Source, Channel, Sink 리소스 변수 정의
	# 8. DriverCarInfo 에이전트 생성
	# 앞서 작성한 SmartCar 에이전트에 DriverCarInfo 에이전트를 위한 Source, Channel, Sink를 추가
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource DriverCarInfo_TailSource
SmartCar_Agent.channels = SmartCarInfo_Channel DriverCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_LoggerSink DriverCarInfo_KafkaSink

	# 2.SmartCar 에이전트 생성
	# 에이전트의 Source를 설정
	# 위에서 선언했던 SmartCarInfo_SpoolSource 라는 변수에 Type을 "spooldir"로 설정
	# "spooldir"은 지정한 특정 디렉터리를 모니터링하고 있다가 새로운 파일이 생성되면 이벤트를 감지해서 "batchSize"의 설정값만큼 읽어서 Channel에 데이터를 전송
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000

	# 6. SmartCar 에이전트에 Interceptor 추가
	# 수집 데이터를 필터링하기 위해 filterInterceptor 변수를 선언해서 SmartCarInfo_SpoolSource에 할당했다
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = filterInterceptor

	# 7. SmartCar 에이전트에 Interceptor 추가
	# filterInterceptor의 Type을 "regex_filter"로 설정했다.
	# Type명에서 알수 있듯이 정규 표현식을 이용해 수집 데이터를 필터링할 때 유용하게 사용할수 있다.
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\\d{14}
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false

	# 3. SmartCar 에이전트 생성
	# 에이전트의 Channel로서 SmartCarInfo_Channel의 Type을 "memory"로 설정했다.
	# 채널의 종류는 크게 Memory와 File이 있다.
	# Memory Channel은 Source로부터 받은 데이터를 메모리상에 중간 적재하므로 성능이 높지만 안정성이 낮다.
	# File Channel의 경우 Source에서 전송한 데이터를 받아 로컬 파일시스템 경로인 "dataDirs"에 임시로 저장했다가 Sink에게 데이터를 제공하므로 성능은 낮지만 안정성이 높다.
SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000

	# 4. SmartCar 에이전트 생성
	# 에이전트의 최종 목적지
	# SmartCarInfo_LoggerSink의 Type을 "logger"로 설정했다.
	# Logger Sink는 수집한 데이터를 테스트 및 디버깅 목적으로 플럼의 표준 출력 로그 파일인 /var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log에 출력한다
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger

	# 5. SmartCar 에이전트 생성
	# Source와 Channel Sink를 연결
	# 앞서 정의한 SmartCarInfo_SpoolSource의 채널값을 SmartCarInfo_Channel로 설정하고, SmartCarInfo_LoggerSink의 채널 값도 SmartCarInfo_Channel로 설정해서 File -> Channel -> Sink로 이어지는 에이전트 리소스를 하나로 연결해 준다.
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channel = SmartCarInfo_Channel

	# 9. DriverCarInfo 에이전트 생성
	# Source의 Type이 "exec"다.
	# "exec"는 플럼 외부에서 수행한 명령의 결과를 플럼의 Event로 가져와 수집할 수 있는 기능을 제공한다.
	# 스마트카 운전자의 운행정보가 로그 시뮬레이터를 통해 /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log 에 생성되는데, 리눅스의 "tail" 명령을 플럼의 "exec"를 실행해서 운전자의 실시간 운행 정보를 수집한다.
SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec
SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log
SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000

SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors = filterInterceptor2

	# 10. DriverCarInfo 에이전트 생성
	# Interceptor를 정의했는데 여기서도 데이터를 필터링하기 위한 "regex_filter"만 추가했다.
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\\d{14}
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false

	# 11. DriverCarInfo 에이전트 생성
	# 스마트카 운전자의 실시간 운행 정보는 플럼에서 수집과 동시에 카프카로 전송한다.
	# 플럼의 KafkaSink의 내용을 보면 카프카 브로커 서버가 실행 중인 server02.hadoop.com:9092에 연결해서 SmartCar-Topic에 데이터를 100개의 배치 크기로 전송한다
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server02.hadoop.com:9092
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000

	# 12. DriverCarInfo 에이전트 생성
	# DriverCarInfo의 Channel을 Memory Channel로 선언
SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
SmartCar_Agent.channels.DriverCarInfo_Channel.capacity= 100000
SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000

	# 13. DriverCarInfo 에이전트 생성
	# DriverCarInfo의 Source와 Sink의 Channel을 앞서 정의한 DriverCarInfo_Channel로 설정해서 Source-Channel-Sink의 구조를 완성했다.
SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel

	[변경내용 저장]


6. 카프카 Topic 생성
	[server02]
	# replication-factor 옵션은 카프카를 다중 Broker로 만들고 전송한 데이터를 replication-factor 개수만큼 복제, 파일럿 환경에서는 1개
	# partitions 옵션은 해당 Topic에 데이터들이 partitions의 개수만큼 분리 저장. 다중 Broker에서 쓰기/읽기 성능 향상을 위해 사용하는 옵션, 파일럿 환경에서는 1개
	# --topic 옵션으로 파일럿 환경에서 사용할 토픽명을 정의, 플럼의 예제 3.4 DriverCarInfo_KafkaSink에서 설정한 토픽이름과 같아야 한다. => SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
	kafka-topics --create --zookeeper server02.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic SmartCar-Topic
	# Created topic "SmartCar-Topic". 메세지 확인
	# 토픽의 메타 정보들이 Zookeeper의 Z노드라는 곳에 만들어지고 관리된다.

	- 토픽 삭제
	kafka-topics --delete --zookeeper server02.hadoop.com:2181 --topic SmartCar-Topic

7. 카프카 Producer 사용
	[server02]
	kafka-console-producer --broker-list server02.hadoop.com:9092 -topic SmartCar-Topic
	> "Hello! BigData!" # 입력, 엔터

8. 카프카 Consumer 사용
	[server02] 새로운 터미널 2개 열기 이후 각각 실행
	kafka-console-consumer --zookeeper server02.hadoop.com:2181 --topic SmartCar-Topic --from-beginning
	# 각각의 창에서 위에서 입력한 Hello BigData 입력된것 확인

