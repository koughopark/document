7월 2일

소프트웨어는 최신이 좋은게 아닐수 있다.


============================================

7월 3일

rdate 날짜 관련
gcc 컴파일러
make 빌더
wget 소프트웨어 외부로 가져올때 크롤링
gcc-c++ 컴파일러
cmake c++ 빌드툴
net-tools 네트워크 관련
bind-utils 네트워크 관리할때 사용
psmisc

ps -ef | grep sshd  # sshd 프로세스 전체 출력

ssh root@192.168.1.163  # 시큐어셀 원격 접속
pass: manager

useradd -g wheel datamaster

ssh datamaster@192.168.1.163
pass: manager

ip: 192.168.1.163

root 로 재접속

vi time_sync.sh

vi -> 입력하려면 i
저장하고 나가려면 esc 누르고 :wq
:w! -> 덮어쓰기

chmod 700 time_sync.sh  # 나만 실행 하겠다

./time_sync.sh  # 현재 시간 확인

mv time_sync.sh /etc/cron.hourly    # etc/corn.hourly 라는 이름으로 이동하겠다(파일이름 붙여주면 리네임해준다)

(w 현재 접속 계정 확인)

vi /etc/sysconfig/selinux
SELINUX = disabled

ps -ef | grep iptables
(iptables 는 방화벽 프로그램)

kill -9 # 9번 시그널(kill)을 보내라.

/etc/init.d/iptables start  # 프로세스 시작
/etc/init.d/iptables stop   # 프로세스 정지

chkconfig  # 리눅스가 시작될때 자동으로 실행되는 데몬 프로그램 출력
chkconfig iptables off

vi /etc/

버추얼 박스에서 프로젝트에서 우클릭 -> 네트워크 초기화 -> 복제
완전한 복제 클릭

복제를 했으니 기존의 환경을 새로운 환경으로 바꾸어 줘야 한다.
------------------

프로젝트2번 시작
root 접속

ifconfig -a

cd /etc
cd sysconfig
cd network-scripts

ls -a
vi ifcfg-eth0
DEVICE 부분도 맞춰준다.
HWADDR 부분을 맥어드레스를 버추얼 환경설정 네트워크와 동기화

ifconfig -a 로 확인했을때 eth(번호) 부분과 동일하게 맞춰준다.
mv ifcfg-eth0 ifcfg-eth1    # mv 명령은 앞의 파일을 뒤의 파일로 바꾼다.

호스트 이름을 바꿔줘야 한다. 현재 lx01 -> lx02
vi /etc/sysconfig/network

요약
1. ifconfig -a 명령어에 나오는 eth 확인
2. vi ifcfg-eth(번호) 실행
3. DEVICE 부분을 동일하게 맞춰준다
4. 버추얼 박스에서 네트워크 설정에서 MACADDRESS 부분과 HWADDR 부분을 동일하게 맞춰준다
5. mv ifcfg-eth0 ifcfg-eth1
6. vi /etc/sysconfig/network 에서 현재 호스트로 변경
7. hosts qusrud

ifconfig 기준으로 맞춘다(디바이스 파일이기 때문에)

/etc/init.d/network restart

# shutdown -h now

=============================================================================================
=============================================================================================
=============================================================================================
[[[[[[[[[[
[my account]
# ip를 셋팅하기위한 조건
lx01 eth2 192.168.1.163
lx02 eth3 192.168.1.188
lx03 eth4 192.168.1.207

netmask 255.255.255.0
network 192.168.1.0  # 뒤에것을 0으로 해주면 된다
gateway 192.168.1.1
nameserver 168.126.63.1
]]]]]]]]]]]]]

[hosts.txt]
192.168.1.72	lx01.hadoop.com
192.168.1.73	lx02.hadoop.com
192.168.1.75	lx03.hadoop.com


cd /etc/sysconfig/network-scripts
[ifcfg-eth()]
BOOTPROTO = static 으로 변경

IPADDR=192.168.1.(ip)

GATEWAY=192.168.1.1
NETMASK=255.255.255.0
NETWORK=192.168.1.0
=============================================================================================
=============================================================================================
=============================================================================================

whoami = 어떤 계정인지 알려준다

passwd
새 비번 enter

-------------------

lx02 프로젝트 실행
passwd
새 비번 enter

vi ifcfg-eth1

------------------------------
------------------------------
------------------------------
cd /etc/sysconfig/network-scripts

ip 작업
xshell 프로그램으로 접속
ssh root@192.168.1.(ip)

1.==
cd /etc/sysconfig/network-scripts

vi ifcfg-eth0

BOOTPROTO = static 으로 변경

IPADDR=192.168.1.(ip)

GATEWAY=192.168.1.1
NETMASK=255.255.255.0
NETWORK=192.168.1.0
:wq

mv ifcfg-eth0 ifcfg-eth1

2.==
---
cd /etc
vi resolv.conf
---
search hadoop.com

nameserver 168.126.63.1
nameserver 168.126.63.2  #예비 서버
---

ssh root@192.168.1.(ip)  # 서버접속


3.==
 yum -y install traceroute       # 라우트 되는것을 추적하겠다.

 traceroute www.google.com

 ping www.google.com


4.==
vi /etc/hosts
192.168.1.163   lx01.hadoop.com lx01
192.168.1.188   lx02.hadoop.com lx02
192.168.1.207   lx03.hadoop.com lx03


5.==
메모장으로 hosts 파일 열기
[하단]
192.168.1.163	lx01.hadoop.com lx01
192.168.1.188	lx02.hadoop.com lx02
192.168.1.207	lx03.hadoop.com lx03


6.==
방화벽 off
/etc/init.d/iptables stop



7.== 클라우데라 설치후
cd /etc/cloudera-scm-agent/
vi config.ini -> ip lx01로 변경
lx02, lx03 도 lx01 ip 로 변경

접속할때 http://lx01(ip):7180/cmf/hardware/hosts


===============================
===============================
===============================

ssh ip=> name으로 변경할수 있다.
C:\Windows\System32\drivers\etc
웹페이지접속하면 hosts open 부터 연다.

메모장으로 hosts 파일 열기
[하단]
192.168.1.163	lx01.hadoop.com lx01
192.168.1.188	lx02.hadoop.com lx02
192.168.1.207	lx03.hadoop.com lx03
추가

#ssh 연결(직접 연결 할때)
ssh root@lx01.hadoop.com
ssh root@lx02.hadoop.com
ssh root@lx03.hadoop.com

------
xshell 에서 새연결
이름: lx01
호스트: lx01.hadoop.com
---
사용자 인증탭: 사용자 이름 : root
----------------

vi /etc/hosts
192.168.1.163   lx01.hadoop.com lx01
192.168.1.188   lx02.hadoop.com lx02
192.168.1.207   lx03.hadoop.com lx03
설정 저장후
ssh로 다른 계정 접속방법
# ssh root@lx03

[브라우저]
lx01.hadoop.com
lx02.hadoop.com
lx03.hadoop.com
======================================
======================================
======================================

7월 4일

root 접속
wget http://archive.cloudera.com/cm5/installer/5.9.0/cloudera-manager-installer.bin
---------=======!!!!!!!!!!!!
wget https://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
sudo chmod u+x cloudera-manager-installer.bin
sudo ./cloudera-manager-installer.bin

설치 완료후 오류나면
sudo tail -F /var/log/cloudera-scm-agent/cloudera-scm-agent.log

sudo more -T /var/log/cloudera-scm-agent/cloudera-scm-agent.log
---------=======!!!!!!!!!!!!

clo

echo $PATH


chmod 700  cloudera-manager-installer.bin

./cloudera-manager-installer.bin

/etc/init.d/cloudera-scm-server status

cloudera-scm-server

(설치중) root1 다시 접속
 -> top 입력 // top은 현재 돌고있는 프로세스 확인.

 /etc/init.d/cloudera-scm-server status

ppt 참고하여 ~68p. 진행

zookeeper 는 클라우데라 속에 포함된 라이브러리
클라우데라는 전체를 관리해주는 라이브러리

카프카는 버퍼링 하는 것

암호화 선택 X

ps -ef | iptables

ps-ef | grep ipt

[오류나면]
vi /etc/cloudera-scm-agent/config.ini
use_tls=0 확인

/etc/init.d/cloudera-scm-agent restart

rpm -qa | grep openssl

/usr/share/cmf/

./uninstall-cloudera-manager.sh

서버재시작
/etc/init.d/cloudera-scm-server restart

=====================================

7월 5일

리퀘스트가 세션을 모아서 접속을 한다. 쿠키에 저장.

rm -f java  # java 파일을 삭제한다.

[lx02]

java 설치 위치
/usr/java

usr/bin
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/java java
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javac javac
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javadoc javadoc
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javaws javaws
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/jps jps
ls -l java*

yum install perl-devel // 이미 인스톨 되어 있음

ppt 107 까지 진행

cd (루트로 이동)

[lx01]

ppt 108 진행
[root@localhost ~]# wget https://www.kernel.org/pub/software/scm/git/git-2.6.4.tar.gz      # 파일 다운로드

[root@localhost ~]# tar xvfz git-2.6.4.tar.gz   # 압축해제

[root@localhost ~]# cd git-2.6.4
[root@localhost git-2.6.4]# ./configure --prefix=/usr/local  # 환경테스트, 설정을 /usr/local 에 저장
Checking for gcc...

[root@localhost git-2.6.4]#make     # 컴파일과 빌드작업을 한다

[root@localhost git-2.6.4]# make install    # usr 밑으로 옮겨준다

git --version

git 설치한 이유는 스마트가 소스 가져오려고

mvn(Maven) = java 빌드해준다 => jar 파일이 나온다.
make = C 빌드해준다

pom.xml

cd 에서

ppt 109
r
echo $PATH

vi /etc/profile # 하단 추가
M2_HOME=/usr/local/maven3.3.9
#export PATH=$PATH:$M2_HOME/bin      # 버전이 변경되었을때 한군데만 수정하도록
export PATH=$PATH:$M2_HOME/bin:$JAVA_HOME/bin   # 윗줄 지우고 이줄로 변경.

mvn

cd /usr/java/jdk1.7.0... #java home

========================================================================================================================
7월 6일

source /etc/profile

[이클립스]
프로젝트 -> 우클릭 -> Run As -> Maven build
gole: mvn clean package

github/bitacademy-bigdata

datamaster@ 에서
mkdir workspace

깃허브 주소 복사후 앞에 http -> git
git://github.com/testestzxcv/smartcarlog.git

datamaster@ [smartcar 디렉토리]
mvn clean install -Dhttps.protocols=TLSv1.2
# mvn -Dhttps.protocols=TLSv1.2 clean install

cd .m2
la -al
cd repository

cp -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10
java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10

mkdir logs

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10

vi log...
tail ..

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100     # 상태정보

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100    #운행정보

tail -f logs/driving.log

rm -rf logs

cd workking

cd home/datamaster/workspace/smartcarlog/working

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

mkdir logs

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

플롬이라는 수집 프로그램을 사용한다
플룸에서 데이터 수집하면 하둡에 저장해준다.

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100

tail -f 가 확인하는 것을 플룸이 하둡에 저장해준다.

풀럼에서 일단 다 모은다.

싱크라는 프로그램
싱크가 하둡이면 하둡으로 가고,
다른 프로그램이면 해당 프로그램으로 간다.

카프카에서 적재까지 하는것이 수집

[3.빅데이터 수집]
17p. ~ 진행

(카프카보다 레디스 프로그램으로 채팅프로그램을 많이 만든다.)

.../smartcar/working/logs/status_20180101.log
.../smartcar/working/logs/driving_20180101.log
.../smartcar/working/logs/flume_spool       # <- flume 프로그램이 지켜보고 있다.


ppt 30~31p 구성설정 복사후
cloudera에 붙여넣기
=====================
# 변수정의
SmartCar.sources  = StatusSource    # DrivingSource
SmartCar.channels = StatusChannel   # DrivingChannel
SmartCar.sinks    = StatusSink  # DrivingSink

# 에이전트의 Source를 설정
SmartCar.sources.StatusSource.type = spooldir
#SmartCar.sources.StatusSource.spoolDir=/home/datamaster/workspace/smartcarlog/working/flume-spool
SmartCar.sources.StatusSource.spoolDir=/home/pilot-pjt/working/car-batch-log
SmartCar.sources.StatusSource.deletePolicy = immediate
SmartCar.sources.StatusSource.batchSize = 1000

SmartCar.sources.StatusSource.interceptors = timeInterceptor typeInterceptor collectDayInterceptor filterInterceptor

# timeInterceptor
SmartCar.sources.StatusSource.interceptors.timeInterceptor.type = timestamp
SmartCar.sources.StatusSource.interceptors.timeInterceptor.preserveExisting = true

# typeInterceptor
SmartCar.sources.StatusSource.interceptors.typeInterceptor.type = static
SmartCar.sources.StatusSource.interceptors.typeInterceptor.key = logType
SmartCar.sources.StatusSource.interceptors.typeInterceptor.value = status

# collectDayInterceptor
SmartCar.sources.StatusSource.interceptors.collectDayInterceptor.type = com.bigdata2017.smartcar.flume.interceptor.CollectDayInterceptor$Builder

# filterInterceptor
SmartCar.sources.StatusSource.interceptors.filterInterceptor.type = regex_filter
SmartCar.sources.StatusSource.interceptors.filterInterceptor.regx = ^\\d{14}
SmartCar.sources.StatusSource.interceptors.filterInterceptor.excludeEvents = false

SmartCar.channels.StatusChannel.type = memory
SmartCar.channels.StatusChannel.capacity = 100000
SmartCar.channels.StatusChannel.transactionCapacity = 10000


# SmartCar.sinks.StatusSink.type = logger
SmartCar.sinks.StatusSink.type = hdfs
SmartCar.sinks.StatusSink.hdfs.path = /smartcar/collection/%{logType}/workdate=%Y%m%d
SmartCar.sinks.StatusSink.hdfs.filePrefix = %{logType}
SmartCar.sinks.StatusSink.hdfs.fileSuffix = .log
SmartCar.sinks.StatusSink.hdfs.fileType = DataStream
SmartCar.sinks.StatusSink.hdfs.writeFormat = Text
SmartCar.sinks.StatusSink.hdfs.batchSize = 10000
SmartCar.sinks.StatusSink.hdfs.rollInterval = 0
SmartCar.sinks.StatusSink.hdfs.rollCount = 0
SmartCar.sinks.StatusSink.hdfs.idleTimeout = 100
SmartCar.sinks.StatusSink.hdfs.callTimeout = 600000
SmartCar.sinks.StatusSink.hdfs.rollSize = 67108864
SmartCar.sinks.StatusSink.hdfs.threadsPoolSize = 10



SmartCar.sources.StatusSource.channels = StatusChannel
SmartCar.sinks.StatusSink.channel = StatusChannel



SmartCar.sources.DrivingSource.type = exec
SmartCar.sources.DrivingSource.command = tail -F /home/datamaster/workspace/smartcarlog/working/logs/driving.log
SmartCar.sources.DrivingSource.restart = true
SmartCar.sources.DrivingSource.batchSize = 1000

SmartCar.channels.DrivingChannel.type = memory
SmartCar.channels.DrivingChannel.capacity= 100000
SmartCar.channels.DrivingChannel.transactionCapacity = 10000

SmartCar.sinks.DrivingSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar.sinks.DrivingSink.topic = SmartCar-Topic
SmartCar.sinks.DrivingSink.brokerList = lx02.hadoop.com:9092
SmartCar.sinks.DrivingSink.requiredAcks = 1
SmartCar.sinks.DrivingSink.batchSize = 1000

SmartCar.sources.DrivingSource.channels = DrivingChannel
SmartCar.sinks.DrivingSink.channel = DrivingChannel
===========================================

36p 진행

[working]

su - # 루트로 변경

cd home/datamaster/workspace/smartcarlog/working

mkdir flume-spool

chown flume:flume flume-spool/  # 소유자를 바꾸겠다.

chmod 705 datamaster/

chown flume:wheel logs

chmod 775 logs

[@datamaster]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

rm -f logs/*

sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

mv ./logs/status_20180101.log ./flume-spool/

rm -f flume-spool/*

ls -l flume-spool/

sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 20

mv ./logs/status_20180101.log ./flume-spool/

ls -l ./flume-spool/

tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

[ppt p33]
kafka-topics --create --zookeeper lx02.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic  SmartCar-Topic

kafka-console-producer  --broker-list lx02.hadoop.com:9092 --topic SmartCar-Topic

[다른 콘솔창에서]
kafka-console-consumer --zookeeper lx02.hadoop.com:2181 --topic SmartCar-Topic --from-beginning  # 전체 다 달라는 의미

ppt 35 기존 메모장에 변경부분 추가
브라우저에서 설정변경후 재시작

[원래 콘솔창 /working 에서]
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100
다른콘솔창에서 로그 확인


------------------------------------------------------


HDFS 클릭 -> NameNode 웹UI (4. 빅데이터 적재 16p)
하이브 한다음에 이곳에 자주오게된다

http://lx01.hadoop.com:8088

ppt 21p
/smartcar/collection/status/workdate=20180101   # 디렉토리
/smartcar/collection/status/workdate=20180102   # 디렉토리

where workdate like '201801'

========================================

[저녁]

깃허브 주소 복사

git clone git://github.com/bitacademy-bigdata/smartcar.flume.interceptor.git


cd smartcar.flume.interceptor/
mvn clean install

mvn clean install -Dhttps.protocols=TLSv1.2

ppt 23p 와 내용 다름
cp release/com.bigdata2017.smartcar.flume.inteceptor-1.0.jar /opt/cloudera/parcels/CDH-5.15.0-1.cdh5.15.0.p0.21/lib/flume-ng/lib/

[다른창에서]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

[원래창 working]- 로그만들기
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 50

mv logs/status_20180101.log flume-spool

[다른창에서]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

hdfs dfs -ls -R /smartcar

책(실무로 배우는 빅데이터 기술) 157p 까지 했다.

hdfs dfs -cat /smartcar/collection/status/workdate=20180706/status.1530874141739.log
hdfs dfs -tail /smartcar/collection/status/workdate=20180706/status.1530874141739.log

[폴더 디렉토리 완전 삭제]
rm -r -f folderName
rm -rf folderName

========================================================================================================================
7월 9일

[lx02 창 2개]
hdfs dfs -ls -R /smartcar   # R은 전체다 불러온다.

컴퓨터에서 가장 느린것은 디스크에 접근할때 가장 느리다.

/home/datamaster/workspace/smartcarlog/working

ls

flume 스테이터스 소스가 -> /working/flume-spool 을 감시하고 있다.

sudo -u flume java  # 플룸으로 자바를 실행하겠다.

tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

[lx02 2번창] /working
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180709 100

mv logs/status_20180709.log flume-spool/

[1창]
hdfs dfs -ls -R /smartcar

hdfs dfs -cat /smartcar/collection/status/workdate=20180709/status.1531100985396.log

kafka-console-consumer --zookeeper lx02.hadoop.com:2181 --topic SmartCar-Topic

[2창]
tail -f logs/driving.log

[3번째 창]
cd /home/da ... working/] tail -f logs/driving.log

[1번창]
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180709 100
2,3번창 로그 출력

--------------------------

[오후시간]

Redis
하둡시스템과 관계없다.
클라우데라에서 설치할수 없다.
캐시에서는 Redis 가 최고다.

RDBMS = 강사님 기준, 최고의 프로그램

ppt23p. ~ 진행

[lx01]

hbase shell

create 'test_table', 'cf'   # 테이블 생성

put 'test_table', 'r1', 'cf:model', 'a001'      # 키값이 r1, 칼럼이 model

put 'test_table', 'r1', 'cf:no', '1'

get 'test_table', 'r1'

drop 'test_table'

disable 'test_table'

drop 'test_table'

exit

[lx02]
id

yum -y install gcc

yum -y install tcl

ppt 33p. ~ 진행
make install
[root@lx02 utils]# pwd
/root/redis-3.0.7/utils
./install_server.sh
# 입력없이 엔터

40p 까지 진행

ls -l /etc/init.d

41p ~ 진행

ls -l /etc/init.d/storm*

chmod 755 /etc/init.d/storm-*

mkdir /var/log/storm
mkdir /var/run/storm
/etc/init.d/storm-nimbus start
/etc/init.d/storm-nimbus status
/etc/init.d/storm-supervisor start
/etc/init.d/storm-supervisor status

[프로세스 검색]
ps -ef | grep nimbus
ps -ef | grep supervisor
ps -ef | grep ui

[중지할때]
/etc/init.d/storm-nimbus stop
/etc/init.d/storm-supervisor stop

tail -f /var/log/storm/

vi /usr/local/storm/conf/storm

ps -ef | grep storm

ls -l /var/run/storm/

(rm -f /var/run/storm/*  # storm 삭제 할때)

[lx02 다른창]  cd /var/log/storm
tail -f storm-nimbus.out
tail -f storm-supervisor.out


[lx02 1창]
/etc/init.d/storm-nimbus start
/etc/init.d/storm-nimbus status
/etc/init.d/storm-supervisor start
/etc/init.d/storm-supervisor status
/etc/init.d/storm-ui start
/etc/init.d/storm-ui status

cd /home/datamaster/workspace/
ls -la
git clone git://github.com/testestzxcv/smartcar.storm.git

ls -l
cd smartcar.storm/
# mvn clean install
mvn clean install -Dhttps.protocols=TLSv1.2

오늘 수업은 토폴로지 만드는것이 키포인트

cd release/
ls -la

작업은 항상 working 에서 한다

[smartcar.storm/]
storm jar release/com.bigdata2017.smartcar.storm-1.0.jar com.bigdata2017.smartcar.storm.SmartCarDrivingTopology SmartCarDriving

[02.2 창]
tail -f /usr/local/storm/logs/worker-6700.log

[02.1]
cd smartcarlog/working
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180709 100

========================================================================================================================

7월 17일

h0: 귀무가설은 전제하는것이지 증명의 대상이 아니다

h1: 대립가설은 증명하고 싶은것 (의미가 있고 흥미가 있는 가설)



========================================================================================================================
7월 18일

pythonic = 파이썬에서만 가능한 문법

immutable = 얕은복제하는 경우 새로운 객체로 분열한다.
mutable = 얕은복제하는 경우 링크 유지.

람다함수 = 익명함수



========================================================================================================================
7월 19일

numpy 는 R을 베이스로 개발되었다.

한줄짜리 행렬이 벡터이다.

컬럼을 나타내기에 최적화 된것이 numpy 배열이다.

컬럼 = 세로
행렬 = 가로

numpy 행렬은 2차원 행렬을 담을수 없다.

알고리즘을 만들때 numpy 필요하다.

알고리즘을 만들때 선형대수학이 필요하다.

2차원 배열이 행렬이다.

a.reshape(3,-1) # -1은 컴퓨터가 알아서 계산해서 채워넣으라는 의미

리스트의 + 는 numpy 에서는 append로 사용
numpy의 + 는 리스트에서는 없다.

선형대수학 = 행렬의 분해 변환에 대해서는 다루지 않는다. 연산을 다룬다.

배열.sum() = np.sum(배열) = np.sum(x*y) = (x * y).sum()

.연산자는 곱한다음에 더한다.

벡터는 방향과 길이가 있다.

-----------------------------

6. 빅데이터 탐색 ppt 설치 진행

설치 완료후 hue 접속
왼쪽 메뉴에서 파일누르면 하둡창 나옴
ppt에서 상단메뉴는 현재 왼쪽위에 있음

메뉴에서 hbase 선택
02콘솔창에서
hbase shell

> count 'table_smartcar_driving'    # 갯수확인

스파크 실행이후
cd /etc
cd hadoop
ls
ppt73p. 오류 -> 얀이 없다

얀 역할인스턴스 게이트웨이 3개다 선택후 설치
dd



========================================================================================================================
7월 23일

변곡점 = 굴곡의 방향이 바뀌는 자리를 나타내는 곡선위의 점.

[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[
############중요하다!!!!!!!!!!!!!!!!!!
Kmeans 최근종가,수익률, 리스크, 베타 기준으로 클러스터 갯수의 최적화:

X=np.array(df.iloc[:,[2,3,4,5]])
n_cluster = np.array(range(2,16))
total_ssw = np.array([])
for n in n_cluster:
    kmeans = KMeans(n_clusters=n)
    clusters = kmeans.fit(X).labels_
    centers = kmeans.cluster_centers_
    total_ssw = np.append(total_ssw, total_ss_within(X,centers,clusters))
plt.plot(n_cluster,total_ssw,color='blue',marker='o',linestyle='dashed',linewidth=1,markersize=5)
plt.show()
]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]



========================================================================================================================
7월 26일

[R]
구글에서 r download 검색해서 다운로드
구글에서 rstudio download 검색해서 다운로드

세션 -> 셋워킹디렉토리-> 츄즈디렉토리 -> 작업폴더 지정

> getwd()

오른쪽 아래 Packages 클릭 (기본형으로 설치된 패키지)

패캐지스에서 이름 클릭하면 헬프도 나온다.

a <- b  # a에 b를 대입

x <- c(x,4,5,6) # x에 x와 4,5,6을 연결 파이썬의 + 와 같다.

R은 인덱스가 1부터 시작한다.

cbind() 컬럼 바인드(행)
rbind() 로우 바인드(렬)

헬프파일을 보는 이유는 인수의 디폴트값을 확인하기 위해서

Factor 는 R에만 있는 독특한 것이다.

콘솔창 지우기 = Ctrl + L

==================================================

[sol_0201.R]
library("hflights")
head(hflights)
str(hflights)
hflights$Dest[1:100]
length(hflights$Dest)

# 도수표를 만들어 보았습니다
CountOfDest <- table(hflights$Dest)
dim(CountOfDest)
CountOfDest

# 최고값과 최대값 찾기
MinMax <- range(CountOfDest)
MinMax

# 최빈도 공항 찾기.
CountOfDest[CountOfDest == MinMax[2]]

# 5000 이상의 공항 찾기.
TopDest <- CountOfDest[CountOfDest >  5000]
TopDest

# 시각화
barplot(TopDest)

=======================================

7월 27일

sapply, tapply 는 그룹연산을 해주는 중요한 함수이다.

========================================================================================================================
7월 31일
로지스틱 회귀(모아니면 도)

로지스틱, SVM, DT, SVDD

[숙제]
1. 산점도 스캐터 플롯 그려서 메일로 (medicisoft00@daum.net)
데이터1. 데이터2. 데이터3. (각각 데이터 찾아서 그린다.)
Z-Score 사용해서 데이터1, 데이터2, 데이터3 을 차례로 그린다.
총 4개
코드하고, 그림 캡쳐한것.
R도 괜찮고, 파이썬도 괜찮고.
2. PCA 특징을 잘 찾아내는 알고리즘(비지도 학습) 알아오기
3. 회귀분석 정의 예제

40개의 특징을 사용해서 특정값을 도출하는것보다 10개로 줄여서 특징을 찾아내는것이 PCA이다.

Z-score: 평균을 0으로 놓고 위아래로 -,+로 나눈것


로지스틱: 1이야 0이야
SVM: 초평면에서 하이퍼 파라미터에서 어떻게 배치해야 하는지 선택하는것.
DT: 디시전 트리
SVDD: 진성, 가성 중 한가지만 학습시키는것.

[개발자]
APM: 아파치, PHP, MySql
TPM:

회귀분석은 딥러닝과 머신러닝의 기본이다.

웨카
Z-score
PCA
교차검증 cross validation
파이썬 tensorflow
산점도 스캐터


========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================