7월 2일

소프트웨어는 최신이 좋은게 아닐수 있다.


============================================

7월 3일

rdate 날짜 관련
gcc 컴파일러
make 빌더
wget 소프트웨어 외부로 가져올때 크롤링
gcc-c++ 컴파일러
cmake c++ 빌드툴
net-tools 네트워크 관련
bind-utils 네트워크 관리할때 사용
psmisc

ps -ef | grep sshd  # sshd 프로세스 전체 출력

ssh root@192.168.1.163  # 시큐어셀 원격 접속
pass: manager

useradd -g wheel datamaster

ssh datamaster@192.168.1.163
pass: manager

ip: 192.168.1.163

root 로 재접속

vi time_sync.sh

vi -> 입력하려면 i
저장하고 나가려면 esc 누르고 :wq
:w! -> 덮어쓰기

chmod 700 time_sync.sh  # 나만 실행 하겠다

./time_sync.sh  # 현재 시간 확인

mv time_sync.sh /etc/cron.hourly    # etc/corn.hourly 라는 이름으로 이동하겠다(파일이름 붙여주면 리네임해준다)

(w 현재 접속 계정 확인)

vi /etc/sysconfig/selinux
SELINUX = disabled

ps -ef | grep iptables
(iptables 는 방화벽 프로그램)

kill -9 # 9번 시그널(kill)을 보내라.

/etc/init.d/iptables start  # 프로세스 시작
/etc/init.d/iptables stop   # 프로세스 정지

chkconfig  # 리눅스가 시작될때 자동으로 실행되는 데몬 프로그램 출력
chkconfig iptables off

vi /etc/

버추얼 박스에서 프로젝트에서 우클릭 -> 네트워크 초기화 -> 복제
완전한 복제 클릭

복제를 했으니 기존의 환경을 새로운 환경으로 바꾸어 줘야 한다.
------------------

프로젝트2번 시작
root 접속

ifconfig -a

cd /etc
cd sysconfig
cd network-scripts

ls -a
vi ifcfg-eth0
DEVICE 부분도 맞춰준다.
HWADDR 부분을 맥어드레스를 버추얼 환경설정 네트워크와 동기화

mv ifcfg-eth0 ifcfg-eth1    # mv 명령은 앞의 파일을 뒤의 파일로 바꾼다.
ifconfig -a 로 확인했을때 eth(번호) 부분과 동일하게 맞춰준다.

호스트 이름을 바꿔줘야 한다. 현재 lx01 -> lx02
vi /etc/sysconfig/network

요약
1. ifconfig -a 명령어에 나오는 eth 확인
2. vi ifcfg-eth(번호) 실행
3. DEVICE 부분을 동일하게 맞춰준다
4. 버추얼 박스에서 네트워크 설정에서 MACADDRESS 부분과 HWADDR 부분을 동일하게 맞춰준다
5. mv ifcfg-eth0 ifcfg-eth1
6. vi /etc/sysconfig/network 에서 현재 호스트로 변경

ifconfig 기준으로 맞춘다(디바이스 파일이기 때문에)

/etc/init.d/network restart

# shutdown -h now

=============================================================================================
=============================================================================================
=============================================================================================
[[[[[[[[[[
[my account]
# ip를 셋팅하기위한 조건
lx01 eth2 192.168.1.163
lx02 eth3 192.168.1.188
lx03 eth4 192.168.1.207

netmask 255.255.255.0
network 192.168.1.0  # 뒤에것을 0으로 해주면 된다
gateway 192.168.1.1
nameserver 168.126.63.1
]]]]]]]]]]]]]

[hosts.txt]
192.168.1.237	lx01.hadoop.com	lx01
192.168.1.238	lx02.hadoop.com	lx02
192.168.1.239	lx03.hadoop.com	lx03


cd /etc/sysconfig/network-scripts
[ifcfg-eth()]
BOOTPROTO = static 으로 변경

IPADDR=192.168.1.(ip)

GATEWAY=192.168.1.1
NETMASK=255.255.255.0
NETWORK=192.168.1.0
=============================================================================================
=============================================================================================
=============================================================================================

whoami = 어떤 계정인지 알려준다

passwd
새 비번 enter

-------------------

lx02 프로젝트 실행
passwd
새 비번 enter

vi ifcfg-eth1

------------------------------
------------------------------
------------------------------
cd /etc/sysconfig/network-scripts

ip 작업
xshell 프로그램으로 접속
ssh root@192.168.1.(ip)

1.==
cd /etc/sysconfig/network-scripts

vi ifcfg-eth0

BOOTPROTO = static 으로 변경

IPADDR=192.168.1.(ip)

GATEWAY=192.168.1.1
NETMASK=255.255.255.0
NETWORK=192.168.1.0
:wq


2.==
---
cd /etc
vi resolv.conf
---
search hadoop.com

nameserver 168.126.63.1
nameserver 168.126.63.2  #예비 서버
---

ssh root@192.168.1.(ip)  # 서버접속


3.==
# yum -y install traceroute       # 라우트 되는것을 추적하겠다.

# traceroute www.google.com

# ping www.google.com


4.==
vi /etc/hosts
192.168.1.237   lx01.hadoop.com lx01
192.168.1.238   lx02.hadoop.com lx02
192.168.1.239   lx03.hadoop.com lx03


5.==
메모장으로 hosts 파일 열기
[하단]
192.168.1.237	lx01.hadoop.com lx01
192.168.1.238	lx02.hadoop.com lx02
192.168.1.239	lx03.hadoop.com lx03


6.==
방화벽 off
/etc/init.d/iptables stop

===============================
===============================
===============================

ssh ip=> name으로 변경할수 있다.
C:\Windows\System32\drivers\etc
웹페이지접속하면 hosts open 부터 연다.

메모장으로 hosts 파일 열기
[하단]
192.168.1.237	lx01.hadoop.com lx01
192.168.1.238	lx02.hadoop.com lx02
192.168.1.239	lx03.hadoop.com lx03
추가

#ssh 연결(직접 연결 할때)
ssh root@lx01.hadoop.com
ssh root@lx02.hadoop.com
ssh root@lx03.hadoop.com

------
xshell 에서 새연결
이름: lx01
호스트: lx01.hadoop.com
---
사용자 인증탭: 사용자 이름 : root
----------------

vi /etc/hosts
192.168.1.237   lx01.hadoop.com lx01
192.168.1.238   lx02.hadoop.com lx02
192.168.1.239   lx03.hadoop.com lx03
설정 저장후
ssh로 다른 계정 접속방법
# ssh root@lx03

[브라우저]
lx01.hadoop.com
lx02.hadoop.com
lx03.hadoop.com
======================================
======================================
======================================

7월 4일

root 접속
wget http://archive.cloudera.com/cm5/installer/5.9.0/cloudera-manager-installer.bin
---------=======!!!!!!!!!!!!
wget https://archive.cloudera.com/cm5/installer/latest/cloudera-manager-installer.bin
sudo chmod u+x cloudera-manager-installer.bin
sudo ./cloudera-manager-installer.bin

설치 완료후 오류나면
sudo tail -F /var/log/cloudera-scm-agent/cloudera-scm-agent.log

sudo more -T /var/log/cloudera-scm-agent/cloudera-scm-agent.log
---------=======!!!!!!!!!!!!

clo

echo $PATH


chmod 700  cloudera-manager-installer.bin

./cloudera-manager-installer.bin

/etc/init.d/cloudera-scm-server status

cloudera-scm-server

(설치중) root1 다시 접속
 -> top 입력 // top은 현재 돌고있는 프로세스 확인.

 /etc/init.d/cloudera-scm-server status

ppt 참고하여 ~68p. 진행

zookeeper 는 클라우데라 속에 포함된 라이브러리
클라우데라는 전체를 관리해주는 라이브러리

카프카는 버퍼링 하는 것

암호화 선택 X

ps -ef | iptables

ps-ef | grep ipt

[오류나면]
vi /etc/cloudera-scm-agent/config.ini
use_tls=0 확인

/etc/init.d/cloudera-scm-agent restart

rpm -qa | grep openssl

/usr/share/cmf/

./uninstall-cloudera-manager.sh

서버재시작
/etc/init.d/cloudera-scm-server restart

=====================================

7월 5일

리퀘스트가 세션을 모야서 접속을 한다. 쿠키에 저장.

rm -f java // java 파일을 삭제한다.

[lx02]

java 설치 위치
/usr/java

usr/bin
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/java java
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javac javac
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javadoc javadoc
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/javaws javaws
ln -s /usr/java/jdk1.7.0_67-cloudera/bin/jps jps
ls -l java*

yum install perl-devel // 이미 인스톨 되어 있음

ppt 107 까지 진행

cd (루트로 이동)

[lx01]

ppt 108 진행
[root@localhost ~]# wget https://www.kernel.org/pub/software/scm/git/git-2.6.4.tar.gz      # 파일 다운로드

[root@localhost ~]# tar xvfz git-2.6.4.tar.gz   # 압축해제

[root@localhost ~]# cd git-2.6.4
[root@localhost git-2.6.4]# ./configure --prefix=/usr/local  # 환경테스트, 설정을 /usr/local 에 저장
Checking for gcc...

[root@localhost git-2.6.4]#make     # 컴파일과 빌드작업을 한다

[root@localhost git-2.6.4]# make install    # usr 밑으로 옮겨준다

git --version

git 설치한 이유는 스마트가 소스 가져오려고

mvn(Maven) = java 빌드해준다 => jar 파일이 나온다.
make = C 빌드해준다

pom.xml

cd 에서

ppt 109

echo $PATH

vi /etc/profile # 하단 추가
M2_HOME=/usr/local/maven3.3.9
export PATH=$PATH:$M2_HOME/bin      # 버전이 변경되었을때 한군데만 수정하도록
export PATH=$PATH:$M2_HOME/bin:$JAVA_HOME/bin   # 윗줄 지우고 이줄로 변경.

mvn

cd /usr/java/jdk1.7.0... #java home

========================================================================================================================
7월 6일

source /etc/profile

[이클립스]
프로젝트 -> 우클릭 -> Run As -> Maven build
gole: mvn clean package

github/bitacademy-bigdata

datamaster@ 에서
mkdir workspace

깃허브 주소 복사후 앞에 http -> git
git://github.com/testestzxcv/smartcarlog.git

datamaster@ [smartcar 디렉토리]
mvn clean install -Dhttps.protocols=TLSv1.2
mvn -Dhttps.protocols=TLSv1.2 clean install

cd .m2
la -al
cd repository

cp -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10
java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10

mkdir logs

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 10

vi log...
tail ..

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100     # 상태정보

java -cp working/smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100    #운행정보

tail -f logs/driving.log

rm -rf logs

cd workking

cd home/datamaster/workspace/smartcarlog/working

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

mkdir logs

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

플롬이라는 수집 프로그램을 사용한다
플룸에서 데이터 수집하면 하둡에 저장해준다.

java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100

tail -f 가 확인하는 것을 플룸이 하둡에 저장해준다.

풀럼에서 일단 다 모은다.

싱크라는 프로그램
싱크가 하둡이면 하둡으로 가고,
다른 프로그램이면 해당 프로그램으로 간다.

카프카에서 적재까지 하는것이 수집

[3.빅데이터 수집]
17p. ~ 진행

(카프카보다 레디스 프로그램으로 채팅프로그램을 많이 만든다.)

.../smartcar/working/logs/status_20180101.log
.../smartcar/working/logs/driving_20180101.log
.../smartcar/working/logs/flume_spool       # <- flume 프로그램이 지켜보고 있다.


ppt 30~31p 구성설정 복사후
cloudera에 붙여넣기
=====================
SmartCar.sources  = StatusSource DrivingSource
SmartCar.channels = StatusChannel DrivingChannel
SmartCar.sinks    = StatusSink DrivingSink



SmartCar.sources.StatusSource.type = spooldir
SmartCar.sources.StatusSource.spoolDir=/home/datamaster/workspace/smartcarlog/working/flume-spool
SmartCar.sources.StatusSource.deletePolicy = immediate
SmartCar.sources.StatusSource.batchSize = 1000

SmartCar.sources.StatusSource.interceptors = timeInterceptor typeInterceptor collectDayInterceptor filterInterceptor

# timeInterceptor
SmartCar.sources.StatusSource.interceptors.timeInterceptor.type = timestamp
SmartCar.sources.StatusSource.interceptors.timeInterceptor.preserveExisting = true

# typeInterceptor
SmartCar.sources.StatusSource.interceptors.typeInterceptor.type = static
SmartCar.sources.StatusSource.interceptors.typeInterceptor.key = logType
SmartCar.sources.StatusSource.interceptors.typeInterceptor.value = status

# collectDayInterceptor
SmartCar.sources.StatusSource.interceptors.collectDayInterceptor.type = com.bigdata2017.smartcar.flume.interceptor.CollectDayInterceptor$Builder

# filterInterceptor
SmartCar.sources.StatusSource.interceptors.filterInterceptor.type = regex_filter
SmartCar.sources.StatusSource.interceptors.filterInterceptor.regx = ^\\d{14}
SmartCar.sources.StatusSource.interceptors.filterInterceptor.excludeEvents = false

SmartCar.channels.StatusChannel.type = memory
SmartCar.channels.StatusChannel.capacity = 100000
SmartCar.channels.StatusChannel.transactionCapacity = 10000


# SmartCar.sinks.StatusSink.type = logger
SmartCar.sinks.StatusSink.type = hdfs
SmartCar.sinks.StatusSink.hdfs.path = /smartcar/collection/%{logType}/workdate=%Y%m%d
SmartCar.sinks.StatusSink.hdfs.filePrefix = %{logType}
SmartCar.sinks.StatusSink.hdfs.fileSuffix = .log
SmartCar.sinks.StatusSink.hdfs.fileType = DataStream
SmartCar.sinks.StatusSink.hdfs.writeFormat = Text
SmartCar.sinks.StatusSink.hdfs.batchSize = 10000
SmartCar.sinks.StatusSink.hdfs.rollInterval = 0
SmartCar.sinks.StatusSink.hdfs.rollCount = 0
SmartCar.sinks.StatusSink.hdfs.idleTimeout = 100
SmartCar.sinks.StatusSink.hdfs.callTimeout = 600000
SmartCar.sinks.StatusSink.hdfs.rollSize = 67108864
SmartCar.sinks.StatusSink.hdfs.threadsPoolSize = 10



SmartCar.sources.StatusSource.channels = StatusChannel
SmartCar.sinks.StatusSink.channel = StatusChannel



SmartCar.sources.DrivingSource.type = exec
SmartCar.sources.DrivingSource.command = tail -F /home/datamaster/workspace/smartcarlog/working/logs/driving.log
SmartCar.sources.DrivingSource.restart = true
SmartCar.sources.DrivingSource.batchSize = 1000

SmartCar.channels.DrivingChannel.type = memory
SmartCar.channels.DrivingChannel.capacity= 100000
SmartCar.channels.DrivingChannel.transactionCapacity = 10000

SmartCar.sinks.DrivingSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar.sinks.DrivingSink.topic = SmartCar-Topic
SmartCar.sinks.DrivingSink.brokerList = lx02.hadoop.com:9092
SmartCar.sinks.DrivingSink.requiredAcks = 1
SmartCar.sinks.DrivingSink.batchSize = 1000

SmartCar.sources.DrivingSource.channels = DrivingChannel
SmartCar.sinks.DrivingSink.channel = DrivingChannel
===========================================

36p 진행

[working]

su - # 루트로 변경

cd home/datamaster/workspace/smartcarlog/working

mkdir flume-spool

chown flume:flume flume-spool/  # 소유자를 바꾸겠다.

chmod 705 datamaster/

chown flume:wheel logs

chmod 775 logs

[@datamaster]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

rm -f logs/*

sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 100

mv ./logs/status_20180101.log ./flume-spool/

rm -f flume-spool/*

ls -l flume-spool/

sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 20

mv ./logs/status_20180101.log ./flume-spool/

ls -l ./flume-spool/

tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

[ppt p33]
kafka-topics --create --zookeeper lx02.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic  SmartCar-Topic

kafka-console-producer  --broker-list lx02.hadoop.com:9092 --topic SmartCar-Topic

[다른 콘솔창에서]
kafka-console-consumer --zookeeper lx02.hadoop.com:2181 --topic SmartCar-Topic --from-beginning  # 전체 다 달라는 의미

ppt 35 기존 메모장에 변경부분 추가
브라우저에서 설정변경후 재시작

[원래 콘솔창 /working 에서]
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenDrivingLog 20180101 100
다른콘솔창에서 로그 확인


------------------------------------------------------


HDFS 클릭 -> NameNode 웹UI (4. 빅데이터 적재 16p)
하이브 한다음에 이곳에 자주오게된다

http://lx01.hadoop.com:8088

ppt 21p
/smartcar/collection/status/workdate=20180101   # 디렉토리
/smartcar/collection/status/workdate=20180102   # 디렉토리

where workdate like '201801'

========================================

[저녁]

깃허브 주소 복사

git clone git://github.com/bitacademy-bigdata/smartcar.flume.interceptor.git


cd smartcar.flume.interceptor/
mvn clean install

mvn clean install -Dhttps.protocols=TLSv1.2

ppt 23p 와 내용 다름
cp release/com.bigdata2017.smartcar.flume.inteceptor-1.0.jar /opt/cloudera/parcels/CDH-5.15.0-1.cdh5.15.0.p0.21/lib/flume-ng/lib/

[다른창에서]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

[원래창 working]- 로그만들기
sudo -u flume java -cp smartcarlog.jar com.bigdata2017.smartcar.GenStatusLog 20180101 50

mv logs/status_20180101.log flume-spool

[다른창에서]
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-lx02.hadoop.com.log

hdfs dfs -ls -R /smartcar

책(실무로 배우는 빅데이터 기술) 157p 까지 했다.

hdfs dfs -cat /smartcar/collection/status/workdate=20180706/status.1530874141739.log
hdfs dfs -tail /smartcar/collection/status/workdate=20180706/status.1530874141739.log

[폴더 디렉토리 완전 삭제]
rm -r -f folderName
rm -rf folderName

========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================
========================================================================================================================