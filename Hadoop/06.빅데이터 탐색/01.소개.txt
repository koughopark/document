탐색은 프로젝트 진행 중 모든 참여자(개발자, 분석가, 관리자, 고객)가 협업 작업을 하는 단계로서 빅데이터 분석의 방향성을 결정 짓는 매우 중요한 단계이다.

1. 하이브 소개
# Hive는 SQL과 유사한 언어인 HiveQL을 제공하는 데이터 웨어하우스 시스템입니다.
	SQL과 매우 유사한 방식으로 하둡 데이터에 접근성을 높인 하이브를 개발
	빅데이터의 가장 대표적인 SQL on Hadoop 제품
	하이브 클라이언트에서 작성한 QL이 맵리듀스 프로그램으로 변환되어 실행된다
	CLI, 웹 콘솔 등으로 하이브 QL 작성 -> (쿼리엔진에 있는)SQL 파서가 하이브 QL을 맵리듀스 프로그램으로 변환 ->	맵리듀스 프로그램 -> 하둡 클러스터에 전송 -> 여러 데이터노드에서 분산 실행
	하이브 DW에서 정의한 데이터베이스, 테이블, 파티션 정보 등이 모두 MetaStore에서 저장 및 관리

2. 스파크 소개
	최근 빅데이터 분야에서 가장 핫한 기술 중 하나
	스파크의 가장 큰 특징은 고성능 인메모리 분석
	스파크는 데이터 가공 처리를 인메모리에서 수행

3. 우지 소개
	방향성 있는 비순환 그래프(DAG)로 정의해서 잡에 시작, 처리, 분기, 종료점 등의 액션으로 구성하는 워크플로
	우지 클라이언트에서 작성한 워크플로는 우지 서버에 전송, 워크플로 메타 정보는 RDBMS에서 별도 관리
	우지 서버에 있는 Coordinator는 우지에 등록된 워크플로를 스케줄링 해주며, 이때 워크플로 엔진이 Action 노드와 Control 노드의 정보를 해석하면서 관련 태스크를 하둡의 클러스터에서 실행
	주요 Action Task는 하이브, 피그, 스쿱 등이 있고, 관련 Action은 최종적으로 하둡의 맵리듀스 프로그램을 기반으로 작동
	실행중인 태스크의 라이프 사이클은 우지 서버가 시작부터 종료까지 추적하면서 모니터링 정보 제공

4. 휴 소개
	복잡도를 숨기고 접근성을 높인 소프트웨어
	다양한 하둡의 에코시스템의 기능들을 웹UI로 통합 제공
	휴의 데이터베이스에서는 휴에 로그인하는 사용자의 계정 관리와 휴에서 사용할 컴포넌트(잡, 하이브, 피그, 우지 등)의 메타 정보 등을 관리한다.
	HDFS, HBase, 하이브, 임팔라를 편리하게 사용하기 위한 웹 에디터를 제공
